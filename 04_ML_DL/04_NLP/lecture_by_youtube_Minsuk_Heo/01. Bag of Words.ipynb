{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 딥러닝 자연어 처리\n",
    "## 01. Bag of Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Bag of Words란?\n",
    "- 간단히, 문장을 숫자로 표현하는 中 하나"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 각각의 문장을 가방안에 넣어둔다고 가정해보자\n",
    "\n",
    "![Bag_of_Word_explain_1](./assets/What_is_Bag_of_Word_1.png)  \n",
    "![Bag_of_Word_explain_2](./assets/What_is_Bag_of_Word_2.png)  \n",
    "![Bag_of_Word_explain_3](./assets/What_is_Bag_of_Word_3.png)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 단어의 출현 빈도를 나타내보자.\n",
    "    - 이렇게 한다면 숫자로 보일 수 있다.\n",
    "\n",
    "![Bag_of_Word_explain_4](./assets/What_is_Bag_of_Word_4.png)  \n",
    "![Bag_of_Word_explain_5](./assets/What_is_Bag_of_Word_5.png)  \n",
    "![Bag_of_Word_explain_6](./assets/What_is_Bag_of_Word_6.png)  \n",
    "![Bag_of_Word_explain_7](./assets/What_is_Bag_of_Word_7.png)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 과연 이 데이터들은 어떻게 활용될 수 있을까?\n",
    "    - 1. 문장의 유사도\n",
    "    ![Sentence_Similarity_1](./assets/Sentence_Similarity_1.png)  \n",
    "    - 2. 머신러닝/딥러닝의 입력값\n",
    "        - 머신러닝/딥러닝의 모델들은 수학적 모델들이 대부분\n",
    "        - 따라서 입력값이 '수치'여야만 함.\n",
    "        ![Model's_input_data_1](./assets/Model's_input_data_1.png)  \n",
    "        - Bag of Word를 활용하면 머신러닝/딥러닝 모델들의 입력값으로 활용 가능\n",
    "        ![Model's_input_data_2](./assets/Model's_input_data_2.png)  \n",
    "            - 수치로 변형된 값이기 때문  \n",
    "            - 머신러닝/딥러닝 모델 구현 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 한계(Limitation)\n",
    "\n",
    "    - 1. Sparsity\n",
    "\n",
    "    ![Limitation_1](./assets/BOG's_Limitation_1.png)  \n",
    "        - 실제로 적용할 때, 단어는 무수히 많음.  \n",
    "        - 이에 따라 벡터의 차원이 기하급수적으로 증가.  \n",
    "        - '0'데이터는 기하급수적으로 증가, '0이 아닌'데이터는 극소수  \n",
    "        - 모델을 학습하고 구동할 때, 계산량이 높아지고 메모리 사용량도 더 높음  \n",
    "    \n",
    "    - 2. Frequent words has more power\n",
    "\n",
    "    ![Limitation_2](./assets/BOG's_Limitation_2.png)  \n",
    "        - 실제로는 첫 번째 문장과 두 번째 문장의 유사도가 높지만, 빈도수만으로 연관성을 파악하기 때문에 세 번째 문장의 유사도가 더 높게 나옴.  \n",
    "\n",
    "    - 3. Ignoring word orders\n",
    "\n",
    "    ![Limitation_3](./assets/BOG's_Limitation_3.png)  \n",
    "        - 단어의 서순에 따라 뜻이 바뀜.  \n",
    "        - Bag of Word 기법은 문장의 뜻을 완전히 무시함.  \n",
    "        - 문맥이 무시된다는 단점.  \n",
    "\n",
    "    - 4. Out of vocabulary\n",
    "\n",
    "    ![Limitation_4](./assets/BOG's_Limitation_4.png)  \n",
    "        - 보지 못한 단어를 처리할 수 없음.  \n",
    "        - 오타, 줄임말 등에 대해서 한계를 보임.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02. N-그램"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. N그램이란?\n",
    "- 간단히. 연속적인 N개의 토큰으로 구성된 것.\n",
    "\n",
    "- 토큰(Token) : 자연어 처리에서 보통 단어나 철자(Character)를 의미\n",
    "    - N개의 토큰으로 구분?\n",
    "        - Word Level : N 개의 단어 씩\n",
    "        - Character Level : N 개의 철자 씩"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) 1-Gram (Unigram)\n",
    "\n",
    "![Unigram_explain_1](./assets/Unigram_explain_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) 2-Gram (Bigram)\n",
    "\n",
    "![Bigram_explain_1](./assets/Bigram_explain_1.png)\n",
    "\n",
    "- fine you는 토큰이 될 수 없음\n",
    "    - 붙어있지 않기 때문 (연속적이지 않다.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) 3-Gram (Trigram)\n",
    "\n",
    "![Trigram_explain_1](./assets/Trigram_explain_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. N그램을 알아야 하는 이유\n",
    " ![Why_N_Gram_1](./assets/Why_N_Gram_1.png)\n",
    " - Bag of Word의 단점을 극복할 수 있음 (단어의 순서 무시)\n",
    " - 다음 단어 예측 가능\n",
    " - 오타 발견 -> 대체 단어 추천 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
