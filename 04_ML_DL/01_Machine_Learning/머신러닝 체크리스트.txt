<머신러닝 성능 올리기>
1. 문제 정의
- 문제 유형 (예:수치 예측, 분류)
- 성능 평가 지표 (수치 예측 : MSE, RMSE, MAE,    분류 : 정확도, f1 score, roc_auc)

2. 탐색적 데이터 분석
2.1 데이터 훑어보기
  - 데이터 양(샘플수, 특성 수...)
  - 특성 이해 
  - 타깃 값 이해 (<-- 예측해야 하는 값)
  - 데이터 세트(훈련/테스트) 분리 (전처리 후에 데이터세트 분리해도 됨)
     (예외 : 경진 대회용 데이터 이미 분리가 되어 있음)

2.3 데이터 시각화
  (1) 수치형 데이터
      - 히스토그램 : 빠르게 데이터를 파악 
         : 상한~하한, 많이 분포한 데이터의 위치
         : 스케일 여부
         : 왜곡도 여부(꼬리가 긴 데이터들은 이후에 정규 분포 형태로 로그 변환)

  (2) 범주형 데이터
      - 바플롯 
        : 타깃값과의 관계 
         (예: 성별이 생존에 어떤영향을 미치는지 (성별 특성의 예측력 파악))
         (예: Pclass가 생존에 어떤 영향을 미치는지 (Pclass 특성의 예측력 파악))
         (참고 : 수치형 데이터의 예측력을 알고 싶다면 범주화(pd.cut) 해서 시각화 해 볼 수 있음)

      - 박스플롯
        : 이상치 검출 (이상치 삭제하면 좋은 성능으로 이어질 가능성)
      (Note.) 데이터값의 가능한 범위는 전문적인 지식이 있어야 하는 문제

   (3) 상관관계 파악
     - 산점도
     - 히트맵(상관계수)
        : 타겟과 특성들의 상관관계(높다면 중요한 특성, 예: 연비와 차중의 관계)
        : 특성과 특성간의 상관관계 (높다면 하나는 삭제 가능, 예: 마일리지와 연식)
      
3. 전처리 : 탐색적 데이터 분석을 통해 전처리 전략
   : pandas 또는 sckikit-learn 모두 사용 가능
   : scikit-learn에서는 Pipeline을 제공

3.1 특성 선택 / 특성 삭제 / 특성 조합
3.2 인코딩
   (1) 레이블 인코딩(순서가 중요하다면)
   (2) 원핫 인코딩 (값의 크고 작음이 없도록 할 때)

3.2 스케일링
   (1) MinMax 스케일링(정규화) : 0~1사이로
   (2) Standardized 스케일링(표준화) : 평균 0, 분산 1
   (3) 로그 스케일링 : 왜곡된 데이터를 정규 분포 형태로(특성 또는 타깃 모두에 변환)


4. 베이스라인 모델
4.1 교차 검증을 통한 모델의 성능 비교 
     : 교차 검증 = 훈련 + 검증
     : 성능 평가 지표 (수치 예측 : MSE, RMSE, MAE,    분류 : 정확도, .....)

(1) 수치 예측
     선형 회귀 (회귀 계수 : 특성의 영향력)
     트리 모델 (특성의 중요도)
     앙상블 모델
     서포트벡터 머신
     kNN

(2) 분류
    로지스틱 회귀 : 이진분류 (회귀 계수 : 특성의 영향력)
    소프트맥스 회귀 :다중분류 (회귀 계수 : 특성의 영향력)
    트리 모델 (특성의 중요도)
    앙상블 모델
    서포트벡터 머신
    kNN
    
5. 성능 올리기
5.1 데이터 측면 <--- 노력을 기울이는게 더 좋은 성능으로 이어지게 됨
    탐색적 데이터 분석을 통해 나온 결과를 다양하게 실험(적용)
    : 결측치 처리, 이상치 제거
    : 특성 추가 또는 삭제, 파생 특성 추가
    : 특성 인코딩, 특성 스케일링

5.2 모델 측면
    - 앙상블 모델 강력
    - 하이퍼파라미터 튜닝 : 그리드 탐색, 랜덤 탐색
   
6. 최종 예측과 성능 평가
   - 테스트 데이터로 예측 
     : 테스트 데이터는 훈련 데이터의 전처리 된 형식과 동일해야 함
     : 테스트 데이터에 대한 정답이 있으면 바로 평가 가능
     : 경진대회용 테스트의 경우 예측 결과를 제출함으로 평가 받을 수 있음
  







